{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupy import ndarray\n",
    "from typing import List, Any, Tuple, Set\n",
    "\n",
    "import cupy\n",
    "import nodeleys as ndl\n",
    "import sys\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "\n",
    "def t_update(ndl):\n",
    "  pending_for_deletion = []\n",
    "  for i in sys.modules:\n",
    "    if i.split('.')[0] == 'nodeleys':\n",
    "      pending_for_deletion.append(i)\n",
    "\n",
    "  # print(pending_for_deletion)\n",
    "    \n",
    "  for i in pending_for_deletion:\n",
    "    del sys.modules[i]\n",
    "\n",
    "  import nodeleys as ndl\n",
    "  return ndl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140028226853136\n",
      "140028226853520\n",
      "--- 0.0042726993560791016 seconds ---\n",
      "--- 0.012156486511230469 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ndl = t_update(ndl)\n",
    "from nodeleys.system.system_func import *\n",
    "from nodeleys.graph import Switch\n",
    "\n",
    "data_x = ndl.Node(cupy.random.normal(size=(1516,1516)), name='x')\n",
    "data_y = ndl.Node(cupy.random.normal(size=(1516,1)), name='y')\n",
    "data_y.is_constant = True\n",
    "\n",
    "w0 = ndl.Node(cupy.random.normal(size=(1516,516)), name='w0')\n",
    "b0 = ndl.Node(cupy.random.normal(size=(1,516)), name='b0')\n",
    "\n",
    "w1 = ndl.Node(cupy.random.normal(size=(516,64)), name='w1')\n",
    "b1 = ndl.Node(cupy.random.normal(size=(1,64)), name='b1')\n",
    "\n",
    "w1r = ndl.Node(cupy.random.normal(size=(516,64)), name='w1r')\n",
    "b1r = ndl.Node(cupy.random.normal(size=(1,64)), name='b1r')\n",
    "\n",
    "rR = ndl.Node(cupy.random.normal(size=(64,64)), name='rR')\n",
    "bR = ndl.Node(cupy.random.normal(size=(1,64)), name='bR')\n",
    "\n",
    "rL = ndl.Node(cupy.random.normal(size=(64,64)), name='rL')\n",
    "bL = ndl.Node(cupy.random.normal(size=(1,64)), name='bL')\n",
    "\n",
    "w2 = ndl.Node(cupy.random.normal(size=(64,1)), name='w2')\n",
    "b2 = ndl.Node(cupy.random.normal(size=(1,1)), name='b2')\n",
    "\n",
    "RANX = ndl.Node(cupy.random.normal(size=(1516, 64)), name='RANX')\n",
    "\n",
    "gamma0 = node_matmul(data_x, w0, 'gamma0')\n",
    "y0 = node_add(b0, gamma0, 'y0')\n",
    "\n",
    "gamma1 = node_matmul(y0, w1, 'gamma1')\n",
    "y1 = node_add(gamma1, b1, 'y1')\n",
    "\n",
    "gamma1r = node_matmul(y0, w1r, 'gamma1r')\n",
    "y1rs = node_add(gamma1r, b1r, 'y1rs')\n",
    "\n",
    "y1r = Switch(y1rs, [gamma1r], [node_mul(y1rs, 0.), node_mul(RANX, y1rs)], ['x<=0', 'x>0'], 'y1r').compile()\n",
    "# y1r = Virtual([y1r_pre], [node_mul(y1r_pre, 0.), y1r_pre], ['[0]<0', '[0]>=0'], 'y1r').compile()\n",
    "\n",
    "gamma_rR = node_matmul(y1r, rR, 'gamma_rR')\n",
    "y_rR = node_add(gamma_rR, bR, 'y_rR')\n",
    "\n",
    "gamma_rL = node_matmul(y1r, rL, 'gamma_rL')\n",
    "y_rL = node_add(gamma_rL, bL, 'y_rL')\n",
    "\n",
    "y_rRL = node_add(y_rR, y_rL, 'y_rRL')\n",
    "\n",
    "merge = node_add(y1r, y_rRL, 'merge')\n",
    "merge2 = node_add(merge, y1, 'merge2')\n",
    "\n",
    "gamma2 = node_matmul(merge2, w2, 'gamma2')\n",
    "y2 = node_add(gamma2, b2, 'y2')\n",
    "\n",
    "diff = node_sub(y2, data_y, 'diff')\n",
    "squared = node_pow(diff, 2., 'squared')\n",
    "redsum = node_redsum(squared, 0, 'redsum')\n",
    "loss = node_div(redsum, 16., 'loss')\n",
    "\n",
    "with tf.GradientTape(persistent=True) as g:\n",
    "  tf_data_x = tf.Variable(tf.convert_to_tensor(data_x.tensor.get()))\n",
    "  tf_data_y = tf.Variable(tf.convert_to_tensor(data_y.tensor.get()))\n",
    "  tf_w0 = tf.Variable(tf.convert_to_tensor(w0.tensor.get()))\n",
    "  tf_b0 = tf.Variable(tf.convert_to_tensor(b0.tensor.get()))\n",
    "  tf_w1 = tf.Variable(tf.convert_to_tensor(w1.tensor.get()))\n",
    "  tf_b1 = tf.Variable(tf.convert_to_tensor(b1.tensor.get()))\n",
    "  tf_w1r = tf.Variable(tf.convert_to_tensor(w1r.tensor.get()))\n",
    "  tf_b1r = tf.Variable(tf.convert_to_tensor(b1r.tensor.get()))\n",
    "  tf_rR = tf.Variable(tf.convert_to_tensor(rR.tensor.get()))\n",
    "  tf_bR = tf.Variable(tf.convert_to_tensor(bR.tensor.get()))\n",
    "  tf_rL = tf.Variable(tf.convert_to_tensor(rL.tensor.get()))\n",
    "  tf_bL = tf.Variable(tf.convert_to_tensor(bL.tensor.get()))\n",
    "  tf_w2 = tf.Variable(tf.convert_to_tensor(w2.tensor.get()))\n",
    "  tf_b2 = tf.Variable(tf.convert_to_tensor(b2.tensor.get()))\n",
    "  tf_RANX = tf.Variable(tf.convert_to_tensor(RANX.tensor.get()))\n",
    "\n",
    "  tf_gamma0 = tf_data_x @ tf_w0\n",
    "  tf_y0 = tf_gamma0 + tf_b0\n",
    "  tf_gamma1 = tf_y0 @ tf_w1\n",
    "  tf_y1 = tf_gamma1 + tf_b1\n",
    "  tf_gamma1r = tf_y0 @ tf_w1r\n",
    "  tf_gamma1rs = tf_y0 @ tf_w1r\n",
    "  print(id(tf_gamma1r))\n",
    "  print(id(tf_gamma1rs))\n",
    "  tf_y1rs = tf_gamma1r + tf_b1r\n",
    "  tf_y1r = tf.where(tf_y1rs <= 0, x=0., y=tf_RANX * tf_y1rs)\n",
    "\n",
    "\n",
    "  tf_gamma_rR = tf_y1r @ tf_rR\n",
    "  tf_y_rR = tf_gamma_rR + tf_bR\n",
    "\n",
    "  tf_gamma_rL = tf_y1r @ tf_rL\n",
    "  tf_y_rL = tf_gamma_rL + tf_bL\n",
    "\n",
    "  tf_y_rRL = tf_y_rR + tf_y_rL\n",
    "\n",
    "  tf_merge = tf_y1r + tf_y_rRL\n",
    "  tf_merge2 = tf_merge + tf_y1\n",
    "  tf_gamma2 = tf_merge2 @ tf_w2\n",
    "  tf_y2 = tf_gamma2 + tf_b2\n",
    "  tf_diff = tf_y2 - tf_data_y\n",
    "  tf_squared = tf_diff ** 2\n",
    "  tf_redsum = tf.reduce_sum(tf_squared, axis=0, keepdims=True)\n",
    "  tf_loss = tf_redsum / 16.\n",
    "  \n",
    "start_time = time.time()\n",
    "grads = g.gradient(tf_loss, [tf_w0, tf_w1, tf_w2, tf_b0, tf_gamma_rR])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "loss.adic.set_as_objective()\n",
    "loss.adic.begin_backprop()\n",
    "w0.get_gradient()\n",
    "w1.get_gradient()\n",
    "w2.get_gradient()\n",
    "b0.get_gradient()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12390472.87312919,   2139131.91203419, -21229394.73145704, ...,\n",
       "          -973567.96846739,   2584570.5112279 ,   2912612.62076973],\n",
       "       [   730617.60103639,   1535289.5466834 ,  -5044188.1051876 , ...,\n",
       "          -702132.47946235,   8383366.10131261,    963839.97658494],\n",
       "       [  2984902.28988521,  16281350.42240268,  20232138.70030956, ...,\n",
       "         -5973123.29090067,  -8639237.57250413, -31459096.37217195],\n",
       "       ...,\n",
       "       [  4772746.07457647, -11624671.07809455,  -7092918.97663552, ...,\n",
       "         -1188942.02413083,  15188460.85241094,  -3854844.37347624],\n",
       "       [ -5415575.0306724 ,  -8067215.95782039, -24026489.18829124, ...,\n",
       "         -3933778.937632  ,  21567098.63651668,  41075402.93925983],\n",
       "       [ -9177572.96674252,  13799767.03081999,  11840310.77443176, ...,\n",
       "         17526664.18345317,    922063.77566141, -12374457.88267857]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0.get_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1516, 516), dtype=float64, numpy=\n",
       "array([[ 12390472.87312918,   2139131.91203419, -21229394.73145703, ...,\n",
       "          -973567.9684674 ,   2584570.51122788,   2912612.62076971],\n",
       "       [   730617.60103637,   1535289.54668338,  -5044188.10518761, ...,\n",
       "          -702132.47946235,   8383366.10131256,    963839.97658497],\n",
       "       [  2984902.28988521,  16281350.4224027 ,  20232138.70030963, ...,\n",
       "         -5973123.29090064,  -8639237.57250413, -31459096.37217199],\n",
       "       ...,\n",
       "       [  4772746.07457647, -11624671.07809454,  -7092918.97663551, ...,\n",
       "         -1188942.02413083,  15188460.85241092,  -3854844.37347623],\n",
       "       [ -5415575.03067242,  -8067215.95782037, -24026489.1882912 , ...,\n",
       "         -3933778.93763197,  21567098.63651669,  41075402.93925986],\n",
       "       [ -9177572.96674253,  13799767.03081998,  11840310.77443176, ...,\n",
       "         17526664.18345312,    922063.7756614 , -12374457.88267863]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -592.80803381,  1758.0489002 ,    38.55142327, ...,\n",
       "         -240.78185257,  -927.29209325,  -177.74273524],\n",
       "       [ 1121.06165473,   225.50427553,  -795.03607837, ...,\n",
       "          -56.40766872,  -713.57003717,  -115.44455186],\n",
       "       [  496.85798588,   462.03444507,  -169.46510907, ...,\n",
       "         1429.10801311,  -978.65279944,  -965.4081674 ],\n",
       "       ...,\n",
       "       [ 1818.18485501,   377.66176783,  -928.11346932, ...,\n",
       "         1872.43182606,    23.89248882,   187.20460361],\n",
       "       [  172.07079311,  1239.20081593,   -42.36847309, ...,\n",
       "         1169.62770012,   187.40491184,  1231.00144376],\n",
       "       [ -693.07603054,   192.02241137,  -209.65612244, ...,\n",
       "        -1076.73504476,  -459.67665045,  -213.56274296]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1516, 64), dtype=float32, numpy=\n",
       "array([[0.02998197, 0.01165974, 0.00654347, ..., 0.02536652, 0.03159917,\n",
       "        0.00160397],\n",
       "       [0.00842244, 0.00736548, 0.02460846, ..., 0.01018342, 0.01251902,\n",
       "        0.00819403],\n",
       "       [0.0368217 , 0.02055938, 0.00604289, ..., 0.01702051, 0.00322675,\n",
       "        0.00610522],\n",
       "       ...,\n",
       "       [0.01166366, 0.00245767, 0.02337791, ..., 0.01227763, 0.03284488,\n",
       "        0.00408779],\n",
       "       [0.00724606, 0.00752893, 0.05104459, ..., 0.00420289, 0.00103354,\n",
       "        0.00346272],\n",
       "       [0.03427997, 0.0105774 , 0.00888279, ..., 0.00255882, 0.03711211,\n",
       "        0.00567789]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_RANX = tf.math.pow(2.7182, RANX.tensor.get()) / tf.math.reduce_sum(tf.math.pow(2.7182, RANX.tensor.get()), axis=1, keepdims=True)\n",
    "softmax_RANX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1516,), dtype=float32, numpy=\n",
       "array([1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "       0.99999994], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(softmax_RANX, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = node_div(node_pow(2.7182, RANX), node_redsum(node_pow(2.7182, RANX), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = node_add(1., softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, Triplet(, , ; /))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.adic.prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_redsum(softmax, 1).tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
